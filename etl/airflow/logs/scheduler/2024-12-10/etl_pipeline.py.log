[2024-12-10T15:15:16.873+0000] {processor.py:157} INFO - Started process (PID=237) to work on /opt/airflow/dags/etl_pipeline.py
[2024-12-10T15:15:16.876+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/etl_pipeline.py for tasks to queue
[2024-12-10T15:15:16.880+0000] {logging_mixin.py:150} INFO - [2024-12-10T15:15:16.879+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline.py
[2024-12-10T15:15:18.566+0000] {logging_mixin.py:150} INFO - [2024-12-10T15:15:18.554+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/etl_pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/etl_pipeline.py", line 204, in <module>
    download_data >> load_data >> extract_counties >> fetch_noaa >> read_data_task >> transform_data_task >> load_data_task
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/taskmixin.py", line 87, in __rshift__
    self.set_downstream(other)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/taskmixin.py", line 229, in set_downstream
    self._set_relatives(task_or_task_list, upstream=False, edge_modifier=edge_modifier)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/taskmixin.py", line 200, in _set_relatives
    f"Tried to create relationships between tasks that don't have DAGs yet. "
airflow.exceptions.AirflowException: Tried to create relationships between tasks that don't have DAGs yet. Set the DAG for at least one task and try again: [<Task(PythonOperator): download_and_extract_kaggle_data>, <Task(PythonOperator): load_data_to_duckdb>]
[2024-12-10T15:15:18.568+0000] {processor.py:838} WARNING - No viable dags retrieved from /opt/airflow/dags/etl_pipeline.py
[2024-12-10T15:15:18.651+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/etl_pipeline.py took 1.786 seconds
[2024-12-10T15:15:48.930+0000] {processor.py:157} INFO - Started process (PID=540) to work on /opt/airflow/dags/etl_pipeline.py
[2024-12-10T15:15:48.934+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/etl_pipeline.py for tasks to queue
[2024-12-10T15:15:48.937+0000] {logging_mixin.py:150} INFO - [2024-12-10T15:15:48.937+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline.py
[2024-12-10T15:15:50.199+0000] {logging_mixin.py:150} INFO - [2024-12-10T15:15:50.192+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/etl_pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/etl_pipeline.py", line 204, in <module>
    download_data >> load_data >> extract_counties >> fetch_noaa >> read_data_task >> transform_data_task >> load_data_task
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/taskmixin.py", line 87, in __rshift__
    self.set_downstream(other)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/taskmixin.py", line 229, in set_downstream
    self._set_relatives(task_or_task_list, upstream=False, edge_modifier=edge_modifier)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/taskmixin.py", line 200, in _set_relatives
    f"Tried to create relationships between tasks that don't have DAGs yet. "
airflow.exceptions.AirflowException: Tried to create relationships between tasks that don't have DAGs yet. Set the DAG for at least one task and try again: [<Task(PythonOperator): download_and_extract_kaggle_data>, <Task(PythonOperator): load_data_to_duckdb>]
[2024-12-10T15:15:50.200+0000] {processor.py:838} WARNING - No viable dags retrieved from /opt/airflow/dags/etl_pipeline.py
[2024-12-10T15:15:50.256+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/etl_pipeline.py took 1.340 seconds
[2024-12-10T15:16:20.090+0000] {processor.py:157} INFO - Started process (PID=823) to work on /opt/airflow/dags/etl_pipeline.py
[2024-12-10T15:16:20.092+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/etl_pipeline.py for tasks to queue
[2024-12-10T15:16:20.094+0000] {logging_mixin.py:150} INFO - [2024-12-10T15:16:20.093+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline.py
[2024-12-10T15:16:21.609+0000] {logging_mixin.py:150} INFO - [2024-12-10T15:16:21.553+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/etl_pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/etl_pipeline.py", line 169, in <module>
    download_data >> load_data >> extract_counties >> read_data_task >> transform_data_task >> load_data_task
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/taskmixin.py", line 87, in __rshift__
    self.set_downstream(other)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/taskmixin.py", line 229, in set_downstream
    self._set_relatives(task_or_task_list, upstream=False, edge_modifier=edge_modifier)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/taskmixin.py", line 200, in _set_relatives
    f"Tried to create relationships between tasks that don't have DAGs yet. "
airflow.exceptions.AirflowException: Tried to create relationships between tasks that don't have DAGs yet. Set the DAG for at least one task and try again: [<Task(PythonOperator): download_and_extract_kaggle_data>, <Task(PythonOperator): load_data_to_duckdb>]
[2024-12-10T15:16:21.611+0000] {processor.py:838} WARNING - No viable dags retrieved from /opt/airflow/dags/etl_pipeline.py
[2024-12-10T15:16:21.672+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/etl_pipeline.py took 1.588 seconds
[2024-12-10T15:16:51.875+0000] {processor.py:157} INFO - Started process (PID=1106) to work on /opt/airflow/dags/etl_pipeline.py
[2024-12-10T15:16:51.877+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/etl_pipeline.py for tasks to queue
[2024-12-10T15:16:51.880+0000] {logging_mixin.py:150} INFO - [2024-12-10T15:16:51.879+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline.py
[2024-12-10T15:16:53.274+0000] {logging_mixin.py:150} INFO - [2024-12-10T15:16:53.264+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/etl_pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/etl_pipeline.py", line 169, in <module>
    download_data >> load_data >> extract_counties >> read_data_task >> transform_data_task >> load_data_task
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/taskmixin.py", line 87, in __rshift__
    self.set_downstream(other)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/taskmixin.py", line 229, in set_downstream
    self._set_relatives(task_or_task_list, upstream=False, edge_modifier=edge_modifier)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/taskmixin.py", line 200, in _set_relatives
    f"Tried to create relationships between tasks that don't have DAGs yet. "
airflow.exceptions.AirflowException: Tried to create relationships between tasks that don't have DAGs yet. Set the DAG for at least one task and try again: [<Task(PythonOperator): download_and_extract_kaggle_data>, <Task(PythonOperator): load_data_to_duckdb>]
[2024-12-10T15:16:53.275+0000] {processor.py:838} WARNING - No viable dags retrieved from /opt/airflow/dags/etl_pipeline.py
[2024-12-10T15:16:53.335+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/etl_pipeline.py took 1.467 seconds
[2024-12-10T15:17:17.322+0000] {processor.py:157} INFO - Started process (PID=1389) to work on /opt/airflow/dags/etl_pipeline.py
[2024-12-10T15:17:17.326+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/etl_pipeline.py for tasks to queue
[2024-12-10T15:17:17.330+0000] {logging_mixin.py:150} INFO - [2024-12-10T15:17:17.330+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline.py
[2024-12-10T15:17:18.767+0000] {logging_mixin.py:150} INFO - [2024-12-10T15:17:18.736+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/etl_pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/etl_pipeline.py", line 169, in <module>
    download_data >> load_data >> extract_counties >> read_data_task >> transform_data_task >> load_data_task
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/taskmixin.py", line 87, in __rshift__
    self.set_downstream(other)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/taskmixin.py", line 229, in set_downstream
    self._set_relatives(task_or_task_list, upstream=False, edge_modifier=edge_modifier)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/taskmixin.py", line 200, in _set_relatives
    f"Tried to create relationships between tasks that don't have DAGs yet. "
airflow.exceptions.AirflowException: Tried to create relationships between tasks that don't have DAGs yet. Set the DAG for at least one task and try again: [<Task(PythonOperator): download_and_extract_kaggle_data>, <Task(PythonOperator): load_data_to_duckdb>]
[2024-12-10T15:17:18.780+0000] {processor.py:838} WARNING - No viable dags retrieved from /opt/airflow/dags/etl_pipeline.py
[2024-12-10T15:17:18.829+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/etl_pipeline.py took 1.520 seconds
[2024-12-10T15:18:20.804+0000] {processor.py:157} INFO - Started process (PID=237) to work on /opt/airflow/dags/etl_pipeline.py
[2024-12-10T15:18:20.806+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/etl_pipeline.py for tasks to queue
[2024-12-10T15:18:20.808+0000] {logging_mixin.py:150} INFO - [2024-12-10T15:18:20.808+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline.py
[2024-12-10T15:18:22.193+0000] {logging_mixin.py:150} INFO - [2024-12-10T15:18:22.184+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/etl_pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/etl_pipeline.py", line 169, in <module>
    download_data >> load_data >> extract_counties >> read_data_task >> transform_data_task >> load_data_task
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/taskmixin.py", line 87, in __rshift__
    self.set_downstream(other)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/taskmixin.py", line 229, in set_downstream
    self._set_relatives(task_or_task_list, upstream=False, edge_modifier=edge_modifier)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/taskmixin.py", line 200, in _set_relatives
    f"Tried to create relationships between tasks that don't have DAGs yet. "
airflow.exceptions.AirflowException: Tried to create relationships between tasks that don't have DAGs yet. Set the DAG for at least one task and try again: [<Task(PythonOperator): download_and_extract_kaggle_data>, <Task(PythonOperator): load_data_to_duckdb>]
[2024-12-10T15:18:22.194+0000] {processor.py:838} WARNING - No viable dags retrieved from /opt/airflow/dags/etl_pipeline.py
[2024-12-10T15:18:22.228+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/etl_pipeline.py took 1.430 seconds
[2024-12-10T15:18:52.812+0000] {processor.py:157} INFO - Started process (PID=539) to work on /opt/airflow/dags/etl_pipeline.py
[2024-12-10T15:18:52.817+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/etl_pipeline.py for tasks to queue
[2024-12-10T15:18:52.821+0000] {logging_mixin.py:150} INFO - [2024-12-10T15:18:52.820+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline.py
[2024-12-10T15:18:54.166+0000] {logging_mixin.py:150} INFO - [2024-12-10T15:18:54.155+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/etl_pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/etl_pipeline.py", line 169, in <module>
    download_data >> load_data >> extract_counties >> read_data_task >> transform_data_task >> load_data_task
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/taskmixin.py", line 87, in __rshift__
    self.set_downstream(other)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/taskmixin.py", line 229, in set_downstream
    self._set_relatives(task_or_task_list, upstream=False, edge_modifier=edge_modifier)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/taskmixin.py", line 200, in _set_relatives
    f"Tried to create relationships between tasks that don't have DAGs yet. "
airflow.exceptions.AirflowException: Tried to create relationships between tasks that don't have DAGs yet. Set the DAG for at least one task and try again: [<Task(PythonOperator): download_and_extract_kaggle_data>, <Task(PythonOperator): load_data_to_duckdb>]
[2024-12-10T15:18:54.168+0000] {processor.py:838} WARNING - No viable dags retrieved from /opt/airflow/dags/etl_pipeline.py
[2024-12-10T15:18:54.202+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/etl_pipeline.py took 1.405 seconds
[2024-12-10T15:19:24.796+0000] {processor.py:157} INFO - Started process (PID=822) to work on /opt/airflow/dags/etl_pipeline.py
[2024-12-10T15:19:24.799+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/etl_pipeline.py for tasks to queue
[2024-12-10T15:19:24.802+0000] {logging_mixin.py:150} INFO - [2024-12-10T15:19:24.801+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline.py
[2024-12-10T15:19:25.997+0000] {logging_mixin.py:150} INFO - [2024-12-10T15:19:25.988+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/etl_pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/etl_pipeline.py", line 169, in <module>
    download_data >> load_data >> extract_counties >> read_data_task >> transform_data_task >> load_data_task
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/taskmixin.py", line 87, in __rshift__
    self.set_downstream(other)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/taskmixin.py", line 229, in set_downstream
    self._set_relatives(task_or_task_list, upstream=False, edge_modifier=edge_modifier)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/taskmixin.py", line 200, in _set_relatives
    f"Tried to create relationships between tasks that don't have DAGs yet. "
airflow.exceptions.AirflowException: Tried to create relationships between tasks that don't have DAGs yet. Set the DAG for at least one task and try again: [<Task(PythonOperator): download_and_extract_kaggle_data>, <Task(PythonOperator): load_data_to_duckdb>]
[2024-12-10T15:19:25.998+0000] {processor.py:838} WARNING - No viable dags retrieved from /opt/airflow/dags/etl_pipeline.py
[2024-12-10T15:19:26.052+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/etl_pipeline.py took 1.268 seconds
[2024-12-10T15:19:56.705+0000] {processor.py:157} INFO - Started process (PID=1105) to work on /opt/airflow/dags/etl_pipeline.py
[2024-12-10T15:19:56.707+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/etl_pipeline.py for tasks to queue
[2024-12-10T15:19:56.709+0000] {logging_mixin.py:150} INFO - [2024-12-10T15:19:56.709+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline.py
[2024-12-10T15:19:57.867+0000] {logging_mixin.py:150} INFO - [2024-12-10T15:19:57.856+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/etl_pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/etl_pipeline.py", line 169, in <module>
    download_data >> load_data >> extract_counties >> read_data_task >> transform_data_task >> load_data_task
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/taskmixin.py", line 87, in __rshift__
    self.set_downstream(other)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/taskmixin.py", line 229, in set_downstream
    self._set_relatives(task_or_task_list, upstream=False, edge_modifier=edge_modifier)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/taskmixin.py", line 200, in _set_relatives
    f"Tried to create relationships between tasks that don't have DAGs yet. "
airflow.exceptions.AirflowException: Tried to create relationships between tasks that don't have DAGs yet. Set the DAG for at least one task and try again: [<Task(PythonOperator): download_and_extract_kaggle_data>, <Task(PythonOperator): load_data_to_duckdb>]
[2024-12-10T15:19:57.870+0000] {processor.py:838} WARNING - No viable dags retrieved from /opt/airflow/dags/etl_pipeline.py
[2024-12-10T15:19:57.908+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/etl_pipeline.py took 1.211 seconds
[2024-12-10T15:20:28.524+0000] {processor.py:157} INFO - Started process (PID=1388) to work on /opt/airflow/dags/etl_pipeline.py
[2024-12-10T15:20:28.528+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/etl_pipeline.py for tasks to queue
[2024-12-10T15:20:28.531+0000] {logging_mixin.py:150} INFO - [2024-12-10T15:20:28.530+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline.py
[2024-12-10T15:20:29.801+0000] {logging_mixin.py:150} INFO - [2024-12-10T15:20:29.792+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/etl_pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/etl_pipeline.py", line 169, in <module>
    download_data >> load_data >> extract_counties >> read_data_task >> transform_data_task >> load_data_task
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/taskmixin.py", line 87, in __rshift__
    self.set_downstream(other)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/taskmixin.py", line 229, in set_downstream
    self._set_relatives(task_or_task_list, upstream=False, edge_modifier=edge_modifier)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/taskmixin.py", line 200, in _set_relatives
    f"Tried to create relationships between tasks that don't have DAGs yet. "
airflow.exceptions.AirflowException: Tried to create relationships between tasks that don't have DAGs yet. Set the DAG for at least one task and try again: [<Task(PythonOperator): download_and_extract_kaggle_data>, <Task(PythonOperator): load_data_to_duckdb>]
[2024-12-10T15:20:29.803+0000] {processor.py:838} WARNING - No viable dags retrieved from /opt/airflow/dags/etl_pipeline.py
[2024-12-10T15:20:29.845+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/etl_pipeline.py took 1.328 seconds
[2024-12-10T15:21:00.386+0000] {processor.py:157} INFO - Started process (PID=1672) to work on /opt/airflow/dags/etl_pipeline.py
[2024-12-10T15:21:00.390+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/etl_pipeline.py for tasks to queue
[2024-12-10T15:21:00.393+0000] {logging_mixin.py:150} INFO - [2024-12-10T15:21:00.392+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline.py
[2024-12-10T15:21:01.854+0000] {logging_mixin.py:150} INFO - [2024-12-10T15:21:01.847+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/etl_pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/etl_pipeline.py", line 169, in <module>
    download_data >> load_data >> extract_counties >> read_data_task >> transform_data_task >> load_data_task
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/taskmixin.py", line 87, in __rshift__
    self.set_downstream(other)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/taskmixin.py", line 229, in set_downstream
    self._set_relatives(task_or_task_list, upstream=False, edge_modifier=edge_modifier)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/taskmixin.py", line 200, in _set_relatives
    f"Tried to create relationships between tasks that don't have DAGs yet. "
airflow.exceptions.AirflowException: Tried to create relationships between tasks that don't have DAGs yet. Set the DAG for at least one task and try again: [<Task(PythonOperator): download_and_extract_kaggle_data>, <Task(PythonOperator): load_data_to_duckdb>]
[2024-12-10T15:21:01.856+0000] {processor.py:838} WARNING - No viable dags retrieved from /opt/airflow/dags/etl_pipeline.py
[2024-12-10T15:21:01.892+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/etl_pipeline.py took 1.518 seconds
[2024-12-10T15:21:20.612+0000] {processor.py:157} INFO - Started process (PID=1955) to work on /opt/airflow/dags/etl_pipeline.py
[2024-12-10T15:21:20.615+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/etl_pipeline.py for tasks to queue
[2024-12-10T15:21:20.617+0000] {logging_mixin.py:150} INFO - [2024-12-10T15:21:20.616+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline.py
[2024-12-10T15:21:21.609+0000] {logging_mixin.py:150} INFO - [2024-12-10T15:21:21.598+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/etl_pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/etl_pipeline.py", line 169, in <module>
    download_data >> load_data >> extract_counties >> read_data_task >> transform_data_task >> load_data_task
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/taskmixin.py", line 87, in __rshift__
    self.set_downstream(other)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/taskmixin.py", line 229, in set_downstream
    self._set_relatives(task_or_task_list, upstream=False, edge_modifier=edge_modifier)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/taskmixin.py", line 200, in _set_relatives
    f"Tried to create relationships between tasks that don't have DAGs yet. "
airflow.exceptions.AirflowException: Tried to create relationships between tasks that don't have DAGs yet. Set the DAG for at least one task and try again: [<Task(PythonOperator): download_and_extract_kaggle_data>, <Task(PythonOperator): load_data_to_duckdb>]
[2024-12-10T15:21:21.610+0000] {processor.py:838} WARNING - No viable dags retrieved from /opt/airflow/dags/etl_pipeline.py
[2024-12-10T15:21:21.657+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/etl_pipeline.py took 1.051 seconds
[2024-12-10T15:21:51.858+0000] {processor.py:157} INFO - Started process (PID=2238) to work on /opt/airflow/dags/etl_pipeline.py
[2024-12-10T15:21:51.861+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/etl_pipeline.py for tasks to queue
[2024-12-10T15:21:51.863+0000] {logging_mixin.py:150} INFO - [2024-12-10T15:21:51.862+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline.py
[2024-12-10T15:21:52.808+0000] {logging_mixin.py:150} INFO - [2024-12-10T15:21:52.799+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/etl_pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/etl_pipeline.py", line 169, in <module>
    download_data >> load_data >> extract_counties >> read_data_task >> transform_data_task >> load_data_task
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/taskmixin.py", line 87, in __rshift__
    self.set_downstream(other)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/taskmixin.py", line 229, in set_downstream
    self._set_relatives(task_or_task_list, upstream=False, edge_modifier=edge_modifier)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/taskmixin.py", line 200, in _set_relatives
    f"Tried to create relationships between tasks that don't have DAGs yet. "
airflow.exceptions.AirflowException: Tried to create relationships between tasks that don't have DAGs yet. Set the DAG for at least one task and try again: [<Task(PythonOperator): download_and_extract_kaggle_data>, <Task(PythonOperator): load_data_to_duckdb>]
[2024-12-10T15:21:52.809+0000] {processor.py:838} WARNING - No viable dags retrieved from /opt/airflow/dags/etl_pipeline.py
[2024-12-10T15:21:52.865+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/etl_pipeline.py took 1.013 seconds
[2024-12-10T15:22:23.135+0000] {processor.py:157} INFO - Started process (PID=2521) to work on /opt/airflow/dags/etl_pipeline.py
[2024-12-10T15:22:23.137+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/etl_pipeline.py for tasks to queue
[2024-12-10T15:22:23.140+0000] {logging_mixin.py:150} INFO - [2024-12-10T15:22:23.140+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline.py
[2024-12-10T15:22:24.159+0000] {logging_mixin.py:150} INFO - [2024-12-10T15:22:24.149+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/etl_pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/etl_pipeline.py", line 169, in <module>
    download_data >> load_data >> extract_counties >> read_data_task >> transform_data_task >> load_data_task
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/taskmixin.py", line 87, in __rshift__
    self.set_downstream(other)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/taskmixin.py", line 229, in set_downstream
    self._set_relatives(task_or_task_list, upstream=False, edge_modifier=edge_modifier)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/taskmixin.py", line 200, in _set_relatives
    f"Tried to create relationships between tasks that don't have DAGs yet. "
airflow.exceptions.AirflowException: Tried to create relationships between tasks that don't have DAGs yet. Set the DAG for at least one task and try again: [<Task(PythonOperator): download_and_extract_kaggle_data>, <Task(PythonOperator): load_data_to_duckdb>]
[2024-12-10T15:22:24.160+0000] {processor.py:838} WARNING - No viable dags retrieved from /opt/airflow/dags/etl_pipeline.py
[2024-12-10T15:22:24.213+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/etl_pipeline.py took 1.086 seconds
[2024-12-10T15:22:55.281+0000] {processor.py:157} INFO - Started process (PID=2804) to work on /opt/airflow/dags/etl_pipeline.py
[2024-12-10T15:22:55.283+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/etl_pipeline.py for tasks to queue
[2024-12-10T15:22:55.285+0000] {logging_mixin.py:150} INFO - [2024-12-10T15:22:55.284+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline.py
[2024-12-10T15:22:56.286+0000] {logging_mixin.py:150} INFO - [2024-12-10T15:22:56.252+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/etl_pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/etl_pipeline.py", line 169, in <module>
    download_data >> load_data >> extract_counties >> read_data_task >> transform_data_task >> load_data_task
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/taskmixin.py", line 87, in __rshift__
    self.set_downstream(other)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/taskmixin.py", line 229, in set_downstream
    self._set_relatives(task_or_task_list, upstream=False, edge_modifier=edge_modifier)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/taskmixin.py", line 200, in _set_relatives
    f"Tried to create relationships between tasks that don't have DAGs yet. "
airflow.exceptions.AirflowException: Tried to create relationships between tasks that don't have DAGs yet. Set the DAG for at least one task and try again: [<Task(PythonOperator): download_and_extract_kaggle_data>, <Task(PythonOperator): load_data_to_duckdb>]
[2024-12-10T15:22:56.288+0000] {processor.py:838} WARNING - No viable dags retrieved from /opt/airflow/dags/etl_pipeline.py
[2024-12-10T15:22:56.335+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/etl_pipeline.py took 1.060 seconds
[2024-12-10T15:23:14.692+0000] {processor.py:157} INFO - Started process (PID=3087) to work on /opt/airflow/dags/etl_pipeline.py
[2024-12-10T15:23:14.695+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/etl_pipeline.py for tasks to queue
[2024-12-10T15:23:14.698+0000] {logging_mixin.py:150} INFO - [2024-12-10T15:23:14.698+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline.py
[2024-12-10T15:23:15.733+0000] {logging_mixin.py:150} INFO - [2024-12-10T15:23:15.723+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/etl_pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/etl_pipeline.py", line 168, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 429, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/operators/python.py", line 166, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 429, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 806, in __init__
    task_group.add(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/task_group.py", line 227, in add
    raise DuplicateTaskIdFound(f"{node_type} id '{key}' has already been added to the DAG")
airflow.exceptions.DuplicateTaskIdFound: Task id 'load_data_to_duckdb' has already been added to the DAG
[2024-12-10T15:23:15.737+0000] {processor.py:838} WARNING - No viable dags retrieved from /opt/airflow/dags/etl_pipeline.py
[2024-12-10T15:23:15.775+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/etl_pipeline.py took 1.089 seconds
[2024-12-10T15:23:16.804+0000] {processor.py:157} INFO - Started process (PID=3153) to work on /opt/airflow/dags/etl_pipeline.py
[2024-12-10T15:23:16.807+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/etl_pipeline.py for tasks to queue
[2024-12-10T15:23:16.810+0000] {logging_mixin.py:150} INFO - [2024-12-10T15:23:16.810+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline.py
[2024-12-10T15:23:17.863+0000] {logging_mixin.py:150} INFO - [2024-12-10T15:23:17.850+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/etl_pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/etl_pipeline.py", line 168, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 429, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/operators/python.py", line 166, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 429, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 806, in __init__
    task_group.add(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/task_group.py", line 227, in add
    raise DuplicateTaskIdFound(f"{node_type} id '{key}' has already been added to the DAG")
airflow.exceptions.DuplicateTaskIdFound: Task id 'load_data_to_duckdb' has already been added to the DAG
[2024-12-10T15:23:17.865+0000] {processor.py:838} WARNING - No viable dags retrieved from /opt/airflow/dags/etl_pipeline.py
[2024-12-10T15:23:17.933+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/etl_pipeline.py took 1.140 seconds
[2024-12-10T15:24:25.002+0000] {processor.py:157} INFO - Started process (PID=237) to work on /opt/airflow/dags/etl_pipeline.py
[2024-12-10T15:24:25.006+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/etl_pipeline.py for tasks to queue
[2024-12-10T15:24:25.008+0000] {logging_mixin.py:150} INFO - [2024-12-10T15:24:25.007+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline.py
[2024-12-10T15:24:26.372+0000] {logging_mixin.py:150} INFO - [2024-12-10T15:24:26.361+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/etl_pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/etl_pipeline.py", line 168, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 429, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/operators/python.py", line 166, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 429, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 806, in __init__
    task_group.add(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/task_group.py", line 227, in add
    raise DuplicateTaskIdFound(f"{node_type} id '{key}' has already been added to the DAG")
airflow.exceptions.DuplicateTaskIdFound: Task id 'load_data_to_duckdb' has already been added to the DAG
[2024-12-10T15:24:26.374+0000] {processor.py:838} WARNING - No viable dags retrieved from /opt/airflow/dags/etl_pipeline.py
[2024-12-10T15:24:26.430+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/etl_pipeline.py took 1.435 seconds
[2024-12-10T15:24:56.673+0000] {processor.py:157} INFO - Started process (PID=540) to work on /opt/airflow/dags/etl_pipeline.py
[2024-12-10T15:24:56.677+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/etl_pipeline.py for tasks to queue
[2024-12-10T15:24:56.681+0000] {logging_mixin.py:150} INFO - [2024-12-10T15:24:56.680+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline.py
[2024-12-10T15:24:58.053+0000] {logging_mixin.py:150} INFO - [2024-12-10T15:24:58.041+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/etl_pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/etl_pipeline.py", line 168, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 429, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/operators/python.py", line 166, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 429, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 806, in __init__
    task_group.add(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/task_group.py", line 227, in add
    raise DuplicateTaskIdFound(f"{node_type} id '{key}' has already been added to the DAG")
airflow.exceptions.DuplicateTaskIdFound: Task id 'load_data_to_duckdb' has already been added to the DAG
[2024-12-10T15:24:58.054+0000] {processor.py:838} WARNING - No viable dags retrieved from /opt/airflow/dags/etl_pipeline.py
[2024-12-10T15:24:58.095+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/etl_pipeline.py took 1.429 seconds
